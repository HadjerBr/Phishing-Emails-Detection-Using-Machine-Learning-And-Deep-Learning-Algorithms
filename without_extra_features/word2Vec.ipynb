{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier:\n",
      "Accuracy: 0.9316893424036281\n",
      "Precision: 0.9313379460802081\n",
      "Recall: 0.9316893424036281\n",
      "Sınıflandırma Raporu:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Fraudulent       0.92      0.84      0.88      1041\n",
      "      Normal       0.94      0.97      0.95      2487\n",
      "\n",
      "    accuracy                           0.93      3528\n",
      "   macro avg       0.93      0.90      0.92      3528\n",
      "weighted avg       0.93      0.93      0.93      3528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "# CSV dosyanızı yükleyin\n",
    "df = pd.read_csv('./data_without_extra_features/lemmatized_and_misspelled_removed_SEFACED.csv', encoding='utf-8')\n",
    "\n",
    "# Corpusu (lemmatize edilmiş belgeler) ve hedef değişkeni çıkarın\n",
    "corpus = df['lemmatized_tokens']\n",
    "y = df['Class_Label']\n",
    "\n",
    "# Metni tokenize edin\n",
    "tokenized_corpus = [word_tokenize(text) for text in corpus]\n",
    "\n",
    "# Word2Vec modelini eğitin\n",
    "word2vec_model = Word2Vec(tokenized_corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Belge gömülerini ortalama kelime vektörlerini kullanarak oluşturan bir fonksiyon\n",
    "def document_embedding(tokens):\n",
    "    vectors = [word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "# Belge gömülerini oluşturun\n",
    "X_word2vec = np.array([document_embedding(tokens) for tokens in tokenized_corpus])\n",
    "\n",
    "# Veri kümesini eğitim ve test setlerine ayırın\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_word2vec, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Lojistik Regresyon modelini başlatın\n",
    "lr_model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Lojistik Regresyon modelini eğitin\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "# Modeli değerlendirin\n",
    "\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "lr_precision = precision_score(y_test, lr_predictions, average='weighted')\n",
    "lr_recall = recall_score(y_test, lr_predictions, average='weighted')\n",
    "\n",
    "print(\"Logistic Regression Classifier:\")\n",
    "print(f\"Accuracy: {lr_accuracy}\")\n",
    "print(f\"Precision: {lr_precision}\")\n",
    "print(f\"Recall: {lr_recall}\")\n",
    "print(\"Sınıflandırma Raporu:\")\n",
    "print(classification_report(y_test, lr_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "Accuracy: 0.9654195011337868\n",
      "Precision: 0.9660396211626434\n",
      "Recall: 0.9654195011337868\n",
      "Sınıflandırma Raporu:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Fraudulent       0.98      0.90      0.94      1041\n",
      "      Normal       0.96      0.99      0.98      2487\n",
      "\n",
      "    accuracy                           0.97      3528\n",
      "   macro avg       0.97      0.95      0.96      3528\n",
      "weighted avg       0.97      0.97      0.96      3528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RF\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Rastgele Orman modelini başlatın\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Rastgele Orman modelini eğitin\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Modeli değerlendirin\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "rf_precision = precision_score(y_test, rf_predictions, average='weighted')\n",
    "rf_recall = recall_score(y_test, rf_predictions, average='weighted')\n",
    "\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(f\"Accuracy: {rf_accuracy}\")\n",
    "print(f\"Precision: {rf_precision}\")\n",
    "print(f\"Recall: {rf_recall}\")\n",
    "print(\"Sınıflandırma Raporu:\")\n",
    "print(classification_report(y_test, rf_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier:\n",
      "Accuracy: 0.8460884353741497\n",
      "Precision: 0.8422861936728206\n",
      "Recall: 0.8460884353741497\n",
      "Sınıflandırma Raporu:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Fraudulent       0.79      0.65      0.71      1041\n",
      "      Normal       0.86      0.93      0.89      2487\n",
      "\n",
      "    accuracy                           0.85      3528\n",
      "   macro avg       0.83      0.79      0.80      3528\n",
      "weighted avg       0.84      0.85      0.84      3528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NB\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Çoklu Naive Bayes modelini başlatın\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Çoklu Naive Bayes modelini eğitin\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Modeli değerlendirin\n",
    "\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "nb_precision = precision_score(y_test, nb_predictions, average='weighted')\n",
    "nb_recall = recall_score(y_test, nb_predictions, average='weighted')\n",
    "\n",
    "print(\"Naive Bayes Classifier:\")\n",
    "print(f\"Accuracy: {nb_accuracy}\")\n",
    "print(f\"Precision: {nb_precision}\")\n",
    "print(f\"Recall: {nb_recall}\")\n",
    "print(\"Sınıflandırma Raporu:\")\n",
    "print(classification_report(y_test, nb_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier:\n",
      "Accuracy: 0.9404761904761905\n",
      "Precision: 0.9408155990361117\n",
      "Recall: 0.9404761904761905\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Fraudulent       0.95      0.84      0.89      1041\n",
      "      Normal       0.94      0.98      0.96      2487\n",
      "\n",
      "    accuracy                           0.94      3528\n",
      "   macro avg       0.94      0.91      0.93      3528\n",
      "weighted avg       0.94      0.94      0.94      3528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM modelini başlat\n",
    "svm_model = SVC()\n",
    "\n",
    "# SVM modelini eğit\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yap\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Modeli değerlendir\n",
    "\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "svm_precision = precision_score(y_test, svm_predictions, average='weighted')\n",
    "svm_recall = recall_score(y_test, svm_predictions, average='weighted')\n",
    "\n",
    "print(\"Support Vector Machine Classifier:\")\n",
    "print(f\"Accuracy: {svm_accuracy}\")\n",
    "print(f\"Precision: {svm_precision}\")\n",
    "print(f\"Recall: {svm_recall}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, svm_predictions))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=maxlen))\n",
    "cnn_model.add(Conv1D(filters=num_filters, kernel_size=kernel_size, activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "cnn_predictions = cnn_model.predict(X_test)\n",
    "cnn_predictions = (cnn_predictions > 0.5).astype(int)\n",
    "\n",
    "cnn_accuracy = accuracy_score(y_test, cnn_predictions)\n",
    "cnn_precision = precision_score(y_test, cnn_predictions, average='weighted')\n",
    "cnn_recall = recall_score(y_test, cnn_predictions, average='weighted')\n",
    "\n",
    "print(\"Convolutional Neural Network Classifier:\")\n",
    "print(f\"Accuracy: {cnn_accuracy}\")\n",
    "print(f\"Precision: {cnn_precision}\")\n",
    "print(f\"Recall: {cnn_recall}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, cnn_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(128, input_shape=(X_train.shape[1], 1))) \n",
    "lstm_model.add(Dense(64, activation='relu'))\n",
    "lstm_model.add(Dropout(0.5))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "lstm_predictions = lstm_model.predict(X_test)\n",
    "lstm_predictions = (lstm_predictions > 0.5).astype(int)\n",
    "\n",
    "\n",
    "lstm_accuracy = accuracy_score(y_test, lstm_predictions)\n",
    "lstm_precision = precision_score(y_test, lstm_predictions, average='weighted')\n",
    "lstm_recall = recall_score(y_test, lstm_predictions, average='weighted')\n",
    "\n",
    "print(\"LSTM Classifier:\")\n",
    "print(f\"Accuracy: {lstm_accuracy}\")\n",
    "print(f\"Precision: {lstm_precision}\")\n",
    "print(f\"Recall: {lstm_recall}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, lstm_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.34259304  0.41239572  0.17739823 ... -0.57248175 -0.2753076\n",
      "   0.13642502]\n",
      " [ 0.0241638   0.11879435  0.32477924 ... -0.80595094 -0.18799649\n",
      "  -0.37546167]\n",
      " [ 0.33062476 -0.31394276  0.5538537  ... -0.71585536 -0.2277005\n",
      "  -0.46150118]\n",
      " ...\n",
      " [ 0.2645029   0.15665384  0.33787295 ... -0.66036075 -0.12096028\n",
      "  -0.03157748]\n",
      " [-0.02474763  0.3378032   0.20469375 ... -0.79250836  0.03731209\n",
      "  -0.19065219]\n",
      " [ 0.06246347  0.3957846   0.19652408 ... -0.6336944  -0.05793769\n",
      "  -0.09663817]]\n"
     ]
    }
   ],
   "source": [
    "print(X_word2vec)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b89b5cfaba6639976dc87ff2fec6d58faec662063367e2c229c520fe71072417"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
