{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        aa  aba  abandon  abandoned  abandonment  abased  abatement  abb  \\\n",
      "0      0.0  0.0      0.0        0.0          0.0     0.0        0.0  0.0   \n",
      "1      0.0  0.0      0.0        0.0          0.0     0.0        0.0  0.0   \n",
      "2      0.0  0.0      0.0        0.0          0.0     0.0        0.0  0.0   \n",
      "3      0.0  0.0      0.0        0.0          0.0     0.0        0.0  0.0   \n",
      "4      0.0  0.0      0.0        0.0          0.0     0.0        0.0  0.0   \n",
      "...    ...  ...      ...        ...          ...     ...        ...  ...   \n",
      "17635  0.0  0.0      0.0        0.0          0.0     0.0        0.0  0.0   \n",
      "17636  0.0  0.0      0.0        0.0          0.0     0.0        0.0  0.0   \n",
      "17637  0.0  0.0      0.0        0.0          0.0     0.0        0.0  0.0   \n",
      "17638  0.0  0.0      0.0        0.0          0.0     0.0        0.0  0.0   \n",
      "17639  0.0  0.0      0.0        0.0          0.0     0.0        0.0  0.0   \n",
      "\n",
      "       abbas  abbey  ...  zinc  zinfandel  zing  zip  zipper  zonal  zone  \\\n",
      "0        0.0    0.0  ...   0.0        0.0   0.0  0.0     0.0    0.0   0.0   \n",
      "1        0.0    0.0  ...   0.0        0.0   0.0  0.0     0.0    0.0   0.0   \n",
      "2        0.0    0.0  ...   0.0        0.0   0.0  0.0     0.0    0.0   0.0   \n",
      "3        0.0    0.0  ...   0.0        0.0   0.0  0.0     0.0    0.0   0.0   \n",
      "4        0.0    0.0  ...   0.0        0.0   0.0  0.0     0.0    0.0   0.0   \n",
      "...      ...    ...  ...   ...        ...   ...  ...     ...    ...   ...   \n",
      "17635    0.0    0.0  ...   0.0        0.0   0.0  0.0     0.0    0.0   0.0   \n",
      "17636    0.0    0.0  ...   0.0        0.0   0.0  0.0     0.0    0.0   0.0   \n",
      "17637    0.0    0.0  ...   0.0        0.0   0.0  0.0     0.0    0.0   0.0   \n",
      "17638    0.0    0.0  ...   0.0        0.0   0.0  0.0     0.0    0.0   0.0   \n",
      "17639    0.0    0.0  ...   0.0        0.0   0.0  0.0     0.0    0.0   0.0   \n",
      "\n",
      "       zoning  zoo  zoom  \n",
      "0         0.0  0.0   0.0  \n",
      "1         0.0  0.0   0.0  \n",
      "2         0.0  0.0   0.0  \n",
      "3         0.0  0.0   0.0  \n",
      "4         0.0  0.0   0.0  \n",
      "...       ...  ...   ...  \n",
      "17635     0.0  0.0   0.0  \n",
      "17636     0.0  0.0   0.0  \n",
      "17637     0.0  0.0   0.0  \n",
      "17638     0.0  0.0   0.0  \n",
      "17639     0.0  0.0   0.0  \n",
      "\n",
      "[17640 rows x 12851 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# CSV dosyanızı yükleyin\n",
    "df = pd.read_csv('./data_without_extra_features/lemmatized_and_misspelled_removed_SEFACED.csv', encoding='utf-8')\n",
    "\n",
    "# Korpusu (lemmatize edilmiş belgeler) çıkarın\n",
    "corpus = df['lemmatized_tokens']\n",
    "\n",
    "# Bir TfidfVectorizer oluşturun\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Korpusu TF-IDF seyrek matrise dönüştürün ve uydurun\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# TF-IDF matrisini bir DataFrame'e dönüştür\n",
    "df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(df_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "# Korpusu (lemmatize edilmiş belgeler) ve hedef değişkeni çıkarın\n",
    "corpus = df['lemmatized_tokens']\n",
    "y = df['Class_Label']\n",
    "\n",
    "# Veri kümesini eğitim ve test setlerine ayırın\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier:\n",
      "Accuracy: 0.9628684807256236\n",
      "Precision: 0.9639319841594494\n",
      "Recall: 0.9628684807256236\n",
      "Sınıflandırma Raporu:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Fraudulent       0.99      0.88      0.93      1041\n",
      "      Normal       0.95      1.00      0.97      2487\n",
      "\n",
      "    accuracy                           0.96      3528\n",
      "   macro avg       0.97      0.94      0.95      3528\n",
      "weighted avg       0.96      0.96      0.96      3528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "# Korpusu (lemmatize edilmiş belgeler) ve hedef değişkeni çıkarın\n",
    "corpus = df['lemmatized_tokens']\n",
    "y = df['Class_Label']\n",
    "\n",
    "# Veri kümesini eğitim ve test setlerine ayırın\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regresyon modelini başlatın\n",
    "lr_model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Logistic Regresyon modelini eğitin\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "# Modeli değerlendirin\n",
    "\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "lr_precision = precision_score(y_test, lr_predictions, average='weighted')\n",
    "lr_recall = recall_score(y_test, lr_predictions, average='weighted')\n",
    "\n",
    "print(\"Logistic Regression Classifier:\")\n",
    "print(f\"Accuracy: {lr_accuracy}\")\n",
    "print(f\"Precision: {lr_precision}\")\n",
    "print(f\"Recall: {lr_recall}\")\n",
    "print(\"Sınıflandırma Raporu:\")\n",
    "print(classification_report(y_test, lr_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "Accuracy: 0.9750566893424036\n",
      "Precision: 0.975374326365474\n",
      "Recall: 0.9750566893424036\n",
      "Sınıflandırma Raporu:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Fraudulent       0.99      0.93      0.96      1041\n",
      "      Normal       0.97      1.00      0.98      2487\n",
      "\n",
      "    accuracy                           0.98      3528\n",
      "   macro avg       0.98      0.96      0.97      3528\n",
      "weighted avg       0.98      0.98      0.97      3528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RF\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Rastgele Orman modelini başlatın\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Rastgele Orman modelini eğitin\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Modeli değerlendirin\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "rf_precision = precision_score(y_test, rf_predictions, average='weighted')\n",
    "rf_recall = recall_score(y_test, rf_predictions, average='weighted')\n",
    "\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(f\"Accuracy: {rf_accuracy}\")\n",
    "print(f\"Precision: {rf_precision}\")\n",
    "print(f\"Recall: {rf_recall}\")\n",
    "print(\"Sınıflandırma Raporu:\")\n",
    "print(classification_report(y_test, rf_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier:\n",
      "Accuracy: 0.953798185941043\n",
      "Precision: 0.9565381925566161\n",
      "Recall: 0.953798185941043\n",
      "Sınıflandırma Raporu:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Fraudulent       1.00      0.84      0.92      1041\n",
      "      Normal       0.94      1.00      0.97      2487\n",
      "\n",
      "    accuracy                           0.95      3528\n",
      "   macro avg       0.97      0.92      0.94      3528\n",
      "weighted avg       0.96      0.95      0.95      3528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NB\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Çoklu Naive Bayes modelini başlatın\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Çoklu Naive Bayes modelini eğitin\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yapın\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Modeli değerlendirin\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "nb_precision = precision_score(y_test, nb_predictions, average='weighted')\n",
    "nb_recall = recall_score(y_test, nb_predictions, average='weighted')\n",
    "\n",
    "print(\"Naive Bayes Classifier:\")\n",
    "print(f\"Accuracy: {nb_accuracy}\")\n",
    "print(f\"Precision: {nb_precision}\")\n",
    "print(f\"Recall: {nb_recall}\")\n",
    "print(\"Sınıflandırma Raporu:\")\n",
    "print(classification_report(y_test, nb_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM modelini başlat\n",
    "svm_model = SVC()\n",
    "\n",
    "# SVM modelini eğit\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Test seti üzerinde tahminler yap\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Modeli değerlendir\n",
    "\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "svm_precision = precision_score(y_test, svm_predictions, average='weighted')\n",
    "svm_recall = recall_score(y_test, svm_predictions, average='weighted')\n",
    "\n",
    "print(\"Support Vector Machine Classifier:\")\n",
    "print(f\"Accuracy: {svm_accuracy}\")\n",
    "print(f\"Precision: {svm_precision}\")\n",
    "print(f\"Recall: {svm_recall}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, svm_predictions))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=maxlen))\n",
    "cnn_model.add(Conv1D(filters=num_filters, kernel_size=kernel_size, activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "cnn_predictions = cnn_model.predict(X_test)\n",
    "cnn_predictions = (cnn_predictions > 0.5).astype(int)\n",
    "\n",
    "cnn_accuracy = accuracy_score(y_test, cnn_predictions)\n",
    "cnn_precision = precision_score(y_test, cnn_predictions, average='weighted')\n",
    "cnn_recall = recall_score(y_test, cnn_predictions, average='weighted')\n",
    "\n",
    "print(\"Convolutional Neural Network Classifier:\")\n",
    "print(f\"Accuracy: {cnn_accuracy}\")\n",
    "print(f\"Precision: {cnn_precision}\")\n",
    "print(f\"Recall: {cnn_recall}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, cnn_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(128, input_shape=(X_train.shape[1], 1))) \n",
    "lstm_model.add(Dense(64, activation='relu'))\n",
    "lstm_model.add(Dropout(0.5))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "lstm_predictions = lstm_model.predict(X_test)\n",
    "lstm_predictions = (lstm_predictions > 0.5).astype(int)\n",
    "\n",
    "\n",
    "lstm_accuracy = accuracy_score(y_test, lstm_predictions)\n",
    "lstm_precision = precision_score(y_test, lstm_predictions, average='weighted')\n",
    "lstm_recall = recall_score(y_test, lstm_predictions, average='weighted')\n",
    "\n",
    "print(\"LSTM Classifier:\")\n",
    "print(f\"Accuracy: {lstm_accuracy}\")\n",
    "print(f\"Precision: {lstm_precision}\")\n",
    "print(f\"Recall: {lstm_recall}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, lstm_predictions))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b89b5cfaba6639976dc87ff2fec6d58faec662063367e2c229c520fe71072417"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
